---
title: "Розділ 4 Лабораторна робота №3. Розвідувальний аналіз даних. Візуалізація"
author: "[Daniil Tereshchenko](https://www.linkedin.com/in/daniil-tereshchenko/), `r format(Sys.time(), '%Y')`"
date: "`r Sys.Date()`"
output: 
  cleanrmd::html_document_clean:
    theme: axist
bibliography: references_lab.bib
---

# Варіація
## Візуалізація розподілу

```{r message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
packageNeed <- c("knitr", "dplyr", "ggplot2", "devtools", "sparklyr",
                 "GGally", "corrplot", "PerformanceAnalytics", "FactoMineR",
                 "factoextra", "funModeling", "desctable", "ade4", "psych",
                 "smacof", "WVPlots", "caret", "car")
lapply(packageNeed, library, character.only = TRUE)
```

```{r message=FALSE, warning=FALSE, paged.print=FALSE}
library(tidyverse)
library(ggplot2)
ggplot(data = diamonds) +
  geom_bar(mapping = aes(x = cut))
```

Частоту для кожного значення категоріальної змінної можна обчислита, наприклад, так:
```{r}
diamonds %>%
  count(cut)
```

Для неперервної змінної доцільно побудувати гістограму:
```{r}
ggplot(data = diamonds) +
  geom_histogram(mapping = aes(x = carat), binwidth = 0.5)
```

Інтервальна таблиця частот, що відповідає гістограмі, може бути обчислена так:
```{r}
diamonds %>%
  count(cut_width(carat, 0.5))
```
Можна побудувати гістограму для певної долі значень:
```{r}
smaller <- diamonds %>% 
  filter(carat < 3)
  
ggplot(data = smaller, mapping = aes(x = carat)) +
  geom_histogram(binwidth = 0.1)
```

Часто буває доцільно поудвати серія гістограм для різних груп спостережень:
```{r}
ggplot(data = smaller, mapping = aes(x = carat, colour = cut)) +
  geom_freqpoly(binwidth = 0.1)
```
Після того, як ми виконали візуалізацію, що ми маємо знайти на цих графіках? Яка може бути послідовність запитань на наступному етапі?  

*Типові запитання з урахуванням специфіка даної задачі можуть виглядати так:

* Які значення є найбільш поширеними? Чому?
* Які значення є рідкісними? Чому? Це відповідає нашим очікуванням?
* Чи бачемо ми якісь незвичайні закономірності? Що може їх пояснити?

Як приклад, гістограма нижче наводить кілька цікавих питань:

* Чому там більше діамантів праворуч від кожного піка, ніж трохи ліворуч від кожного піка?
* Чому немає діамантів більше 3 каратів?
```{r}
ggplot(data = smaller, mapping = aes(x = carat)) + 
         geom_histogram(binwidth = 0.01)
```
## Незвичайні значення

Як правило у вибіркових даних зустірчаються викиди (outliers) – такі значення свідчать або про похибку вимірювання, або про якість надзвичайні причини, що потребують уважного вивчення.
```{r}
ggplot(diamonds) + 
  geom_histogram(mapping = aes(x = y), binwidth = 0.5)
```

Для того, щоб їх побачити, необхідно певним чином масштабувати гістограму:
```{r}
ggplot(diamonds) + 
  geom_histogram(mapping = aes(x = y), binwidth = 0.5) +
  coord_cartesian(ylim = c(0, 50))
```
Якщо приймається рішення їх видалити, то це можна зроити наступним чином:
```{r}
unusual <- diamonds %>%
  filter(y < 3 | y > 20) %>% 
  select(price, x,y,z) %>%
  arrange(y)
unusual
```

## Пропущені значення (Missing values)
```{r}
diamonds
```

```{r}
diamonds2 <- diamonds %>%
  mutate(y = ifelse( y < 3 | y > 20, NA, y))
```

```{r}
ggplot(data = diamonds2, mapping = aes(x = x, y = y)) + 
  geom_point()
```
Інколи ми хочемо зрозуміти, що робить спостереження з відсутніми значеннями, відмінними від спостережень із записаними значеннями. Наприклад, у `nycflights13::flights`, відсутні значення в змінній `dep_time` (час вильоту) показують, що рейс був скасований. Тому, можливо, нам потрібно буде порівняти заплановані терміни вильоту для скасованих та не скасованих часів. Ми можемо зробити це, зробивши нову змінну з `is.na()`:
```{r}
nycflights13::flights %>% 
  mutate(
    cancelled = is.na(dep_time),
    sched_hour = sched_dep_time %/% 100,
    sched_min = sched_dep_time %% 100,
    sched_dep_time = sched_hour + sched_min / 60
  ) %>% 
  ggplot(mapping = aes(sched_dep_time)) + 
    geom_freqpoly(mapping = aes(colour = cancelled), binwidth = 1/4)
```
# Коваріація

Якщо варіація описує поведінку в межах змінної, коваріація описує поведінку між змінними.  
__Коваріація (Covariation)__ -- це схильність значень двох чи більше змінних змінюватися разом. Найкращим способом виявлення коваріації є візуалізація відносин між двома чи більше змінних.  
```{r}
ggplot(data = diamonds, mapping = aes(x = price)) +
  geom_freqpoly(mapping = aes(colour = cut), binwidth = 500)
```
Важко побачити різницю в розподілах, оскільки кількість вибіркових значень у кожній групі суттєво відрізняється:
```{r}
ggplot(diamonds) +
  geom_bar(mapping = aes(x = cut))
```
Для полегшення порівняння нам потрібно поміняти те, що відображається на осі Y. Замість того, щоб відображати частоту, ми покажемо відносну частоту, яка є нормованою величиною.
```{r}
ggplot(data = diamonds, mapping = aes(x = price, y = ..density..)) +
  geom_freqpoly(mapping = aes(colour = cut), binwidth = 500)
```
В результаті можна побачити, що найвищу середню ціну мають посередні діаманти (fair). Але аналіз щільностей розпоілів є не зовсім зручним. Альтернативним варіантом представлення аналогічної інформації є п’ятиквантильний графік (boxplot, box and wiskers plot), відомий як “боксплот,” або “ящик з вусами.” Боксплот акумулює в собі всі найважливіші інтегральні харакетристики стосовно мір центральної тенденції, розсіювання та форми розподілу.Тоді для нашого випадку застосування боксплотів дасть такий результат:
```{r}
ggplot(data = diamonds, mapping = aes(x = cut, y = price)) +
  geom_boxplot()
```
## Дві категоріальні змінні

Для візуалізації коваріації між категоріальними змінними неохідно візуалізувати частоти: у вигляді таблиці, або певного графічного візуалізатора. Наприклад:
```{r}
ggplot(data = diamonds) +
  geom_count(mapping = aes(x = cut, y = color) )
```
З результатів видно, що існує певна залежність між кольором діаманта, та якістю його ограненості.

# Виконання індивідуального завдання

Дані з досліджуваного набору мають наступний вигляд:
```{r}
iris %>%
  head()
```
Обчислимо і дослідимо сумарні статистики.
```{r}
iris %>%
  df_status()
```
Що ми бачимо? 

* всі дані мають числову природу
* дані комплектні: відстуні пропущені значення
* відсутні нульові значення -- це знімає можливі проблеми при трансформації
* відсутні надвелики значення -- надвелики значення кожен раз потребують серйозної уваги і аналізу можливих причин, що їх викликали
* по всіх змінних дані мають варіацію по унікальним значенням одного порядку.  

Дослідимо закони розподілу кожної з чотирьох змінних.


```{r}
iris %>%
  plot_num()
```

```{r}
iris %>%
  profiling_num()
```
Що ми бачимо?  

* статистичні розподіли змінних `"Sepal.Length"`, `"Sepal.Width"` мають дзвоноподібну форму, наближену до нормального. Враховуючи, що значення оцінок асимметрії та ексцесу несуттєво відрізняються від нуля, в першому наближенні можна вважати дані розподіли нормальними. Про що це говорить і що це дає? По-перше, це говорить про те, що доля малих і великих даних врівноважують одна одну, по-друге, нормальність законів розподілу досліджуваних величин, або, принаймні, "натяк" на нормальність __завжди добре__, тому що класичними передумовами для коректної побудови великої кількості різного роду моделей вимагає від даних нормального закону розподілу, чи, принаймні, симетричності закону розподілу. В нашому випадку це є передумовою однорідного розподілу спостережень у просторі інформативних ознак, що є позитивним моментом при вирішенні задачі сегментації.  
* статистичні розподіли змінних `"Petal.Length"`, `"Petal.Width"` на відміну від двох інших, мають чітку бімодальну структуру, що гооврить про явно виражену неоднорідність даних і про те, що саме ці дві змінні є дискримінуючими у просторі досліджуваних ознак; це важливо для побудови задачі сегментації

Для відповіді на питання, чи пов'язані між собою змінні, застосуємо кореляційний аналіз. З урахуванням числової природи даних, для оцінки кореляції скористаємося коефіцієнтом кореляції Пірсона. Враховуючі багатомірний аналіз початкових даних, важливо вдало підібрати візуалізатор. Нижче запропоновано два з найбільш відомих і поширених.

```{r}
iris %>%
  select(-Species) %>%
      cor() %>%
  corrplot(order = "hclust", tl.col = 'black', tl.cex = .75)
```

```{r}
iris %>%
  select(-Species) %>%
  pairs(main = "Edgar Anderson's Iris Data", font.main = 4, pch = 19, col = iris$Species)
```

```{r}
df_iris <- iris %>%
  select(-Species) 

df_iris %>%
  cor() %>%
  knitr::kable(caption = "Таблиця оцінок коефіцієнтів кореляції")
```
Що ми бачимо? 

* має місце сильний позитивний кореляційний зв'язок між змінною `Sepal.Length` та змінними  `Petal.Length`, `Petal.Width`; на кореляційних полях чітко видно наявність даної кореляції
* на кореляційних полях чітко видно наявність неоднородності даних -- дані чітко поділяються на гомогенні групи за змінною `Species`
* має місце слабкий від'ємний кореляційний зв'язок `Petal.Length` і `Sepal.Width`; дана кореляція є уявною в силу сегментованості даних по змінній `Species`: якщо уважно дослідити форму кореляційних полів для кожного значення данної змінної, то можна побачити, що всередині кожного сегменту має місце позитивна кореляція

Що це нам дає?  

* наявність високого ступеня кореляції дає можливість знизити розмірність даних і знайти просту структуру у просторі меншої розмірності 
* у просторі меншої розмірності можна можна виконати сегментацію даних.

Для зниження розмірності і одночасно сегментації даних скористаємося методом головних компонент (PCA).

```{r}
#PCA
resPCA <- iris %>%
  select(-Species) %>%
  PCA(ncp = 8, graph = FALSE)
```

```{r}
eigenvalues <- as.data.frame(resPCA$eig)
cumVar <- round(eigenvalues$`cumulative percentage of variance`[length(eigenvalues$eigenvalue[eigenvalues$eigenvalue >= 0.9])], 2)
```

```{r}
knitr::kable(
  eigenvalues, 
  caption = "Власні значення (eigenvalues) і сумарний процент поясненої дисперсії"
)
```

```{r}
fviz_screeplot(resPCA, addlabels = TRUE,  ncp=10)
```
Чщо ми бачимо?  
Ми маємо $p=$ `r length(eigenvalues$eigenvalu[eigenvalues$eigenvalue >= 0.9])` головних компонент, які пояснюють `r cumVar` % дисперсії. Це значить, що м маємо всього дві нові компоненти замість чотирьох і практично без втрати інформації можемо представити всі спостереження в системі двох координат на площині: перша компонента по осі `Х`, друга -- по осі Y (див. рис.).  
Проаналізуємо детально структуру двох перших компонент, виключивши решту незначимих (див. табл. і рис.).
```{r}
knitr::kable(
  resPCA$var$coord[ ,1:2], 
  caption = "Таблиця навантажень"
)
```
Що ми бачимо?

* Структуру першої компоненти головним чином складають три початкові змінні: `Sepal.Length`,  `Petal.Length`, `Petal.Width`; як і прогнозувалося раніше, саме за цією компонентою відбувається дискримінація (розрізнення) трьох різних сегментів трьох типів ірисів
* основне навантаження на другу компоненту складає змінна `Sepal.Width` -- всі три види ірисів можуть мати досить велику варіацію за цим параметром.

```{r}
# Biplot of individuals and variables
fviz_pca_biplot(resPCA,
                geom = c("point"),
                # label = "none", # hide individual labels
             habillage = as.factor(iris$Species), # color by groups
             axes = c(1, 2),
             repel = TRUE,
             label = c("ind", "ind.sup", "quali", "var", "quanti.sup"),
             select.var = list(name = c("Sepal.Length", "Sepal.Width", "Petal.Length", "Petal.Width")),
             # select.var = list(contrib = 8),
             # label = c("ind.sup"),
             palette = c("#00AFBB", "#E7B800", "#FC4E07", "#00AFBB", "#E7B800", "#FC4E07"),
             # alpha.var = c("contrib"),
             # col.ind = c("contrib"),
             # col.ind.sup = c("contrib"),
             addEllipses = TRUE # Concentration ellipses
             ) +
  theme_minimal()
```

Таким чином, з’ясовано, шо початкові дані не є однорідними. Три типи ірисів різняться за довжинами внутрішніх часток оцвітини (petal length) та шириною внутрішньої частки оцвітини (petal width). Завдяки наявності кореляцій у початкових змінних, спостереження вдалося добре описати у просторі двох інтегральних показників. Знайдені кластери характерні для трьох типів ірисів і у майбутньому можуть бути використані для написання класифікатора з метою розпізнавання нових об’єктів.



